---
title: "Data Manipulation and Visualization"
author: "Instructors: Daniel Falster & Will Cornwell"
date: "17/12/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction to data manipulation with `dplyr` intro

(Will, 11:15 - 12:15)

## Motivation

Data is never organized in the way you want it 

High % of project is data wrangling

Many many many modern jobs are data wrangling

## Key ideas

Data is a noun

Actions on data are verbs  

Learn a few key verbs and what they do

read_csv

filter

select

mutate

arrange

distinct


group_by

summarise

count 

n

rename

the `join` family

Pipes

- use the operator `%>%` 
- If you use RStudio, you can type the pipe with Ctrl + Shift + M if you have a PC or Cmd + Shift + M if you have a Mac.

**Exercises:**

**Resources:**

- [Data manipulation on environmentalcomputing.net](http://environmentalcomputing.net/data-manipulation/) 
- [Datacarpentry's lesson on data manipulation](https://datacarpentry.org/R-ecology-lesson/03-dplyr.html)
- [The `tidylog` package](https://github.com/elbersb/tidylog) is cool for understanding what happens with dplyr operations

# Lunch

(12:30-13:30)


# Data Wrangling

(13:30-14:00)

**Exercises:** Apply the `dplyr` package and your new data wrangling skills to the sydney beaches dataset to 

1. Create a subset of the dataset consisting of only records taken since 2016
2. As above and only variables `Site`, `Latitude`, and `Longitude`
3. As above but with only one record per Site
3. As above but with data sorted by `Latitude`
4. For each Site, calculate the number of records, the min, mean, median and max value of `Enterococci_cfu_per_100ml` 
5. For each record, create a new variable giving the year the record was collected (hint: the package lubridate could be helpful, see the cheatsheet) 
